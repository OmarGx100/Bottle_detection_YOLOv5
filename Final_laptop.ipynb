{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# import needed dependencies\n",
    "\n",
    "#import yolo \n",
    "from ultralytics import YOLO\n",
    "\n",
    "# import torch \n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# import os and PIL for model evaluation \n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# import cv2 for image handling\n",
    "import cv2\n",
    "\n",
    "\n",
    "#import numpy\n",
    "import numpy as np\n",
    "\n",
    "#importing mqtt dependencies\n",
    "import paho.mqtt.client as mqtt\n",
    "import time\n",
    "\n",
    "\n",
    "#chechking torch version\n",
    "print(torch.__version__)\n",
    "\n",
    "#setting manual seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#clearing out the allocated storage used by the previous model\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING MODEL INTO DIFFERENT FORMATS AND COMPARING THE RESULTS\n",
    "#model.export(format = 'onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFUALT MODEL FORMAT \n",
    "model_path = os.path.join('.', 'runs', 'detect', 'train6', 'weights', 'best.pt')\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL WITH NCNN FORMAT\n",
    "model_ncnn_path = os.path.join('.', 'runs', 'detect', 'train6', 'weights','best.torchscript')\n",
    "model_ncnn = YOLO(model_ncnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL WITH ONNX FORMAT \n",
    "model_onnx_path = os.path.join('.', 'runs', 'detect', 'train6', 'weights','best.onnx')\n",
    "model_onxx = YOLO(model_onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarm\\AppData\\Local\\Temp\\ipykernel_820\\1890974757.py:3: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client  = mqtt.Client(mqtt.CallbackAPIVersion.VERSION1,client_id)\n"
     ]
    }
   ],
   "source": [
    "# create a client to send data to the plc\n",
    "def start_connection_with_mqtt(client_id, MqttBroker):\n",
    "    client  = mqtt.Client(mqtt.CallbackAPIVersion.VERSION1,client_id)\n",
    "    client.connect(MqttBroker)\n",
    "    return client\n",
    "\n",
    "def publish_message(client, message, topic):\n",
    "    client.publish(topic, message)\n",
    "    print(f\"Published: {message} to topic {topic}\")\n",
    "    #time.sleep(0.1)\n",
    "node_red_client_new = start_connection_with_mqtt(\"bottle\", \"broker.hivemq.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_plc_signal(client, class_id, topic):\n",
    "    publish_message(client, class_id, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(frame, predictions, half_frame_up, half_frame_down):\n",
    "\n",
    "   # Get image dimensions\n",
    "    height, width, _ = frame.shape\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for pred in predictions:\n",
    "\n",
    "        # Extracxting needed data from model predictions\n",
    "        class_id, confidence = pred.boxes.data.tolist()[0][5], pred.boxes.data.tolist()[0][4]\n",
    "        class_name_dict = pred.names\n",
    "        x_center, y_center, bbox_width, bbox_height = pred.boxes.xywhn.tolist()[0]\n",
    "        if confidence > 0.7 :\n",
    "        # some visualization to see what is happening\n",
    "            down = (int(x_center * width), 0)\n",
    "            up = (int(x_center * width), height)\n",
    "            cv2.line(frame, pt1 = down, pt2 = up, color = (255, 255, 255), thickness=2)\n",
    "            \n",
    "            # Convert relative coordinates to absolute coordinates\n",
    "            x1 = int((x_center - bbox_width / 2) * width)\n",
    "            y1 = int((y_center - bbox_height / 2) * height)\n",
    "            x2 = int((x_center + bbox_width / 2) * width)\n",
    "            y2 = int((y_center + bbox_height / 2) * height)\n",
    "            \n",
    "            #checking weither the center point crosses the center of the camera frame or not \n",
    "            #if x_center * width == (width / 2):\n",
    "            if x_center * width >= (width / 2) - 15 and x_center * width <= (width / 2) + 15 :\n",
    "                cv2.line(img = frame, pt1= half_frame_up, pt2 = half_frame_down, color = (0, 0, 0), thickness = 3)\n",
    "                # send 1 to the node-red and wait for acknowladgement then send the class id\n",
    "                send_plc_signal(node_red_client_new, 1, \"bottle_detected_new\")\n",
    "                send_plc_signal(node_red_client_new, class_id + 2, \"bottle_color_new\")\n",
    "            \n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(img = frame, pt1 = (x1, y1), pt2 = (x2, y2), color = (0, 255, 0), thickness = 2)\n",
    "            \n",
    "            # Write class label and confidence\n",
    "            label = f'{class_name_dict[class_id]}: accu :{confidence:.2f}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) \n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drwaing a line in the middle of the camera frame so we can notice if the process is going correctly or not\n",
    "# Here we are just declaring the cordinates of the line \n",
    "half_frame_down = (320, 0)\n",
    "half_frame_up = (320,480)\n",
    "\n",
    "\n",
    "#choosing two differenct colors so if the bottle in the middle we change that color also to see if the process is going correctly\n",
    "color1= (0, 255, 0)\n",
    "color2 = (255, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# to calculate the fps we need to calculate the starting time that that process starts and also when it ends\n",
    "start_time = 0\n",
    "# end time \n",
    "end_time = 0\n",
    "\n",
    "while True :\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret :\n",
    "        break\n",
    "    \n",
    "    # Doing forward path with inference mode so that the model does not tweak its perameters\n",
    "    with torch.inference_mode():\n",
    "        results = model_ncnn(frame)\n",
    "\n",
    "    # checking if there are results ----> visualizting predictions\n",
    "    if len(results[0].boxes.data) != 0 :\n",
    "        frame = visualize_predictions(frame, results, half_frame_up, half_frame_down)\n",
    "    \n",
    "    # If there is no predictions then initialize the messages sent to node red with zero\n",
    "    else :\n",
    "        # One to stop convyer and the other to tell the bottle color\n",
    "        send_plc_signal(node_red_client_new, 0, \"bottle_detected_new\")\n",
    "        send_plc_signal(node_red_client_new, 0, \"bottle_color_new\")\n",
    "\n",
    "    #Calculating the whole process time \n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculating the fps\n",
    "    fps = int(1/(end_time - start_time))\n",
    "    fps2 = f\"FPS : {fps}\"\n",
    "    start_time = end_time\n",
    "    \n",
    "    #writing the fps on the screen\n",
    "    cv2.putText(frame, fps2, (10, 35),cv2.FONT_HERSHEY_SIMPLEX, 1.6, (0, 255, 0), 2)\n",
    "\n",
    "    # opening the web cam with predictions\n",
    "    cv2.imshow(\"predictions\", frame)\n",
    "\n",
    "\n",
    "    # if you press s then break the programm\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break\n",
    "\n",
    "# release all allocated memory \n",
    "cap.release()\n",
    "\n",
    "# destroying the windows\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
